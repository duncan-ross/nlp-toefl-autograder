{"lr": 7.224369639799431e-06, "lr_decay": false, "max_epochs": 30, "batch_size": 32, "model_name": "hierarchical", "stopping_epoch": 1, "loss": 0.6257753684005065}