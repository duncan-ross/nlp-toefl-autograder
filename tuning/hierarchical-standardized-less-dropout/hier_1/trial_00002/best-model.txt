{"lr": 2.8627901287627263e-05, "lr_decay": false, "max_epochs": 30, "batch_size": 32, "model_name": "hierarchical", "stopping_epoch": 0, "loss": 0.6185648722195486}